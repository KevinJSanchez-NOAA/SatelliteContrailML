{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ea7090-2a21-46f5-ae21-e3e50b2f77f2",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Import Packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb437a0-ae1e-4c58-83f8-4f78626be60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', '/home/builder/ktietz/aggregate/tensorflow_recipes/ci_cpu/tensorflow-base_1614583966145/_build_env/bin/x86_64-conda_cos6-linux-gnu-gcc'), ('cuda_compute_capabilities', ['compute_35', 'compute_52', 'compute_60', 'compute_61', 'compute_70', 'compute_75']), ('cuda_version', '10.1'), ('cudnn_version', '7'), ('is_cuda_build', True), ('is_rocm_build', False)])\n",
      "cuda version:  10.1\n",
      "cudNN version:  7\n",
      "TF version:  2.4.1\n",
      "5924\n",
      "5924\n"
     ]
    }
   ],
   "source": [
    "### -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 24 13:26:13 2021\n",
    "\n",
    "@author: kjsanche\n",
    "\n",
    "Description: \n",
    "A function to load the 5 minute granules from MODIS channel 1 \n",
    "(0.65 microns) and the contrail mask for ML with a CNN.\n",
    "\n",
    "To do:\n",
    "ASAP:\n",
    "-create blacklist of images to exclude (if images are to big)\n",
    "-separate testing data\n",
    "-plot testing data vs mask\n",
    "\n",
    "\n",
    "\n",
    "lower priority:\n",
    "-optimize image shape by transforming back to original satellite swath projection\n",
    "-save and set up to load data as tfrecord\n",
    "-organize/markdown/comment code\n",
    "\n",
    "\n",
    "Input:\n",
    "Path   (string)\n",
    "\n",
    "        \n",
    "        \n",
    "Output:\n",
    "MODISCh1 (2D uint32)\n",
    "MASK     (2D uint16)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from UNET_Functions import unet_model, summary\n",
    "from Sat_contrail_read import Extract_RawDef, extract_img, extract_mask, extract_imglist, get_model_memory_usage\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.ndimage import rotate\n",
    "from format_input import *\n",
    "import tensorflow as tf\n",
    "\n",
    "sys_details = tf.sysconfig.get_build_info()\n",
    "print(sys_details)\n",
    "cudnn_version = sys_details[\"cudnn_version\"]\n",
    "cuda_version = sys_details[\"cuda_version\"]\n",
    "\n",
    "print('cuda version: ', cuda_version)\n",
    "print('cudNN version: ',cudnn_version)\n",
    "print('TF version: ', tf.version.VERSION)\n",
    "\n",
    "\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.experimental.output_all_intermediates(True) \n",
    "path = os.getcwd()\n",
    "proj_path = os.path.normpath(path + os.sep + os.pardir) #get parent directory\n",
    "image_path = '/home/kjsanche/Desktop/ExternalSSD/SatContrailData/' #os.path.join(proj_path, 'data/')\n",
    "save_TFrecord_path = '/home/kjsanche/Desktop/ExternalSSD/SatContrailData/TFrecords/' \n",
    "\n",
    "\n",
    "image0065, image0380, image0680, image0850, image1100, image1200, image1330, AUX_list, mask_list = extract_imglist(image_path)\n",
    "\n",
    "N = len(image0065)\n",
    "print(N)\n",
    "print(len(image0380))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b38ec73-a0fb-44a8-9c96-c15a6e094d7d",
   "metadata": {},
   "source": [
    "## extract image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "559d3ea0-5d48-4dd4-95d3-0a2a01463fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = Extract_RawDef(AUX_list)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a37d8304-004f-48f0-8f6f-3d3d00aeb60c",
   "metadata": {},
   "source": [
    "for path in zip(img1100_list_ds.take(3), mask_list_ds.take(3)):\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d5b6aa-f366-4cd9-b425-6357a187da43",
   "metadata": {},
   "source": [
    "## make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6e7d274-a27b-4cae-a890-740e141c1323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5924,)\n",
      "(5924,)\n"
     ]
    }
   ],
   "source": [
    "img0065_filenames = tf.constant(image0065)\n",
    "img0380_filenames = tf.constant(image0380)\n",
    "img0680_filenames = tf.constant(image0680)\n",
    "img0850_filenames = tf.constant(image0850)\n",
    "img1100_filenames = tf.constant(image1100)\n",
    "img1200_filenames = tf.constant(image1200)\n",
    "img1330_filenames = tf.constant(image1330)\n",
    "\n",
    "masks_filenames = tf.constant(mask_list)\n",
    "print(img1100_filenames.shape)\n",
    "print(masks_filenames.shape)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((img0065_filenames, img0380_filenames, img0680_filenames, img0850_filenames, img1100_filenames, img1200_filenames, img1330_filenames, masks_filenames, dim))\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c91ac33-4329-4868-a728-f8fbd8c41682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: ((4096, 4096, 7), (4096, 4096, 1)), types: (tf.float16, tf.int8)>\n"
     ]
    }
   ],
   "source": [
    "def process_path(img0065_path, img0380_path, img0680_path, img0850_path, img1100_path, img1200_path, img1330_path, mask_path,dim):\n",
    "# convert binary files to matrix of integers\n",
    "\n",
    "    img1 = extract_img(str(img0065_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "    img2 = extract_img(str(img0380_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "    img3 = extract_img(str(img0680_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "    img4 = extract_img(str(img0850_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "    img5 = extract_img(str(img1100_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "    img6 = extract_img(str(img1200_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "    img7 = extract_img(str(img1330_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "\n",
    "    img = np.concatenate((img1, img2, img3, img4, img5, img6, img7), axis=2)\n",
    "    \n",
    "    mask = extract_mask(str(mask_path.numpy().decode('ascii')),int(dim[0].numpy()),int(dim[1].numpy()))\n",
    "   \n",
    "    return tf.convert_to_tensor(img,dtype=tf.float16), tf.convert_to_tensor(mask,dtype=tf.int8)\n",
    "\n",
    "def preprocess(image, mask):\n",
    "    input_image = tf.image.resize(image, (2048, 4096), method='nearest')\n",
    "    #print(img)\n",
    "    input_mask = tf.image.resize(mask, (2048, 4096), method='nearest')\n",
    "    #input_image(input_image>0) = 1\n",
    "    input_image = (input_image-25500) / np.float16(7500) # assuming range of 180-330 K (BT is multiplied by 100)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "def _set_shapes(img, mask):\n",
    "    img.set_shape([4096, 4096, 7])\n",
    "    mask.set_shape([4096, 4096, 1])\n",
    "\n",
    "    return img, mask \n",
    "\n",
    "#print(dataset)\n",
    "image_ds = dataset.map(lambda aa, bb, cc, dd, ee, ff, gg, hh, ii: tf.py_function(process_path, [aa, bb, cc, dd, ee, ff, gg, hh, ii], [tf.float16, tf.int8]))\n",
    "image_ds = image_ds.map(_set_shapes)\n",
    "print(image_ds)\n",
    "#processed_image_ds = image_ds.map(preprocess)\n",
    "\n",
    "#print(processed_image_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4073e92-44b2-451c-ab1a-3173fb9b4c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        print(i)\n",
    "        print(display_list[i].shape)\n",
    "        if i == 0:\n",
    "            plt.imshow(np.float32(display_list[i][:,:,0]-display_list[i][:,:,1]))\n",
    "        else:\n",
    "            plt.imshow(np.float32(1*display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95823e8e-cea2-4843-a8a1-88d23a1950da",
   "metadata": {},
   "source": [
    "The below code cell uses a lot of memory and therefore should not be used during training."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b19460a-73a7-4864-9525-8a2ae348e154",
   "metadata": {},
   "source": [
    "for image, mask in image_ds.take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    #print(mask.shape)\n",
    "display([sample_image, sample_mask])\n",
    "print('mem usage: ', tf.config.experimental.get_memory_usage(\"GPU:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5a0955-6d0d-4d04-9121-699b51606b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 4096, 7)\n"
     ]
    }
   ],
   "source": [
    "for image, mask in image_ds.take(1):\n",
    "    sample_image, sample_mask = image, mask\n",
    "print(sample_image.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fd1a6d0-4c97-4d47-ace8-0ba0acb10ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_img(image, angle):\n",
    "    rotated_image =  rotate(np.float32(image), angle=angle, reshape=True, order=0)\n",
    "    #zoom into minimum bounding rectangle\n",
    "    y_min, y_max, x_min, x_max = [np.min(np.nonzero(rotated_image)[0][:]), np.max(np.nonzero(rotated_image)[0][:]), np.min(np.nonzero(rotated_image)[1][:]), np.max(np.nonzero(rotated_image)[1][:])]\n",
    "\n",
    "    return rotated_image, y_min, y_max, x_min, x_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee85e54-e92a-4148-b2d6-4c3437997231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce536e82-71cc-4b32-92f1-10c709f95c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/01__1km.raw\n",
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/20__1km.raw\n",
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/27__1km.raw\n",
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/29__1km.raw\n",
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/31__1km.raw\n",
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/32__1km.raw\n",
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/33__1km.raw\n",
      "/home/kjsanche/Desktop/ExternalSSD/SatContrailData/2018MYD/109/A2018109.1540/MYD021KM-A2018109.1540.contrail-mask\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No points given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-596c2faa1b79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#extract convexhull coordinates, first point and last point must be the same.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mhull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvexHull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mhull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mhull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhull\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhull\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull.ConvexHull.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mqhull.pyx\u001b[0m in \u001b[0;36mscipy.spatial.qhull._Qhull.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No points given"
     ]
    }
   ],
   "source": [
    "#################################################################\n",
    "# Check why sometimes images are full of nans\n",
    "# double check mask names (used for save names)  align (masks and images align at least)\n",
    "##################################################################\n",
    "\n",
    "fileList=tf.io.gfile.glob([save_TFrecord_path + '*.tfrecords'])\n",
    "cnt = 0\n",
    "\n",
    "for image, mask in image_ds:\n",
    "    sample_image, sample_mask = image, mask\n",
    "    filename = mask_list[cnt][-36:-14] \n",
    "    cnt+=1\n",
    "    \n",
    "    #skip file if file already exists or nans/inf values are in images\n",
    "    if save_TFrecord_path+'1_1' + filename + '.tfrecords' in fileList:\n",
    "        continue\n",
    "    if np.any(np.isnan(sample_image)) or np.any(np.isinf(sample_image)):\n",
    "        #print('img')\n",
    "        continue #sys.exit()\n",
    "    if np.any(np.isnan(sample_mask)) or np.any(np.isinf(sample_mask)):\n",
    "        #print('mask')\n",
    "        continue #sys.exit()\n",
    "        \n",
    "        \n",
    "        \n",
    "    #find coordinates of all nonzero coordinates\n",
    "    nonzero =np.asarray(np.nonzero(np.float32(sample_image[:,:,0]))).T\n",
    "\n",
    "    #extract convexhull coordinates, first point and last point must be the same. \n",
    "    hull = ConvexHull(nonzero)\n",
    "    hull = np.vstack((nonzero[hull.vertices,0],nonzero[hull.vertices,1])).T\n",
    "    hull = np.vstack((hull,hull[0,:]))\n",
    "\n",
    "    #calculate angle of rotation for minimum bounding rectangle\n",
    "    angle, barea, bwidth, bheight, center_point, corner_points = minBoundingRect(hull)\n",
    "    \n",
    "    rotated_image, y_min, y_max, x_min, x_max = rotate_img(sample_image, angle=90-angle*180/np.pi)\n",
    "    rotated_labels, _, _, _, _ = rotate_img(sample_mask, angle=90-angle*180/np.pi)\n",
    "    \n",
    "    w = x_max-x_min\n",
    "    h = y_max-y_min\n",
    "    \n",
    "    #determine min/max dimensions\n",
    "    maxCaseDim = np.max([w,h])\n",
    "    minCaseDim = np.min([w,h])\n",
    "\n",
    "    #rotate 90 degrees to make width the bigger side if needed\n",
    "    if h > w:\n",
    "        rotated_image, y_min, y_max, x_min, x_max = rotate_img(rotated_image, angle=90)\n",
    "        rotated_image_zoom = rotated_image[y_min:y_max,x_min:x_max]\n",
    "        rotated_labels, _, _, _, _ = rotate_img(rotated_labels, angle=90)\n",
    "        rotated_labels_zoom = rotated_labels[y_min:y_max,x_min:x_max]\n",
    "    else:\n",
    "        rotated_image_zoom = rotated_image[y_min:y_max,x_min:x_max]\n",
    "        rotated_labels_zoom = rotated_labels[y_min:y_max,x_min:x_max]\n",
    " \n",
    "    #make images and mask have same h x w (2048,4096)\n",
    "    mask = np.zeros((2048,4096,1), dtype = float)\n",
    "    mask[0:rotated_labels_zoom.shape[0], 0:rotated_labels_zoom.shape[1]] += rotated_labels_zoom\n",
    "    img_test = np.zeros((2048,4096,7), dtype = float)\n",
    "    img_test[0:rotated_image_zoom.shape[0], 0:rotated_image_zoom.shape[1], :] += rotated_image_zoom\n",
    "\n",
    "    \n",
    "    #resize images to decreased resolution\n",
    "    img_test = cv2.resize(img_test, dsize=(2048, 1024), interpolation=cv2.INTER_NEAREST)\n",
    "    mask = cv2.resize(mask, dsize=(2048, 1024), interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    #add missing dimensions\n",
    "    img_test = np.expand_dims(img_test, axis=0)\n",
    "    mask = np.expand_dims(mask, axis=0)\n",
    "    #print(mask.shape)\n",
    "    #print(img_test.shape)\n",
    "    \n",
    "    #normalize img and set mask to 1\n",
    "    mask[mask>1]=1\n",
    "    mask = np.int8(mask)\n",
    "    img_test = (img_test-25500) / np.float32(7500) # assuming range of 180-330 K (BT is multiplied by 100)\n",
    "    img_test = np.float16(img_test)\n",
    "    write_images_to_tfr_long(img_test, mask, filename=filename, max_files=1, out_dir=save_TFrecord_path)\n",
    "\n",
    "\n",
    "    #display([sample_image,rotated_image_zoom])\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b23095e-6961-458e-8232-d84fb54d3172",
   "metadata": {},
   "outputs": [],
   "source": [
    "display([img_test,mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce0d8d-3852-4fa5-b247-c1336dab55eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4152e-095b-4f46-9aa9-7c0378c99cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292929ae-7977-4526-99d2-5de1472b7d45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393fef5-f8cd-4478-91e8-428a4136d788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aad604-1cbc-48da-a87d-4c0dc5f194c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
