{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ea7090-2a21-46f5-ae21-e3e50b2f77f2",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Import Packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb437a0-ae1e-4c58-83f8-4f78626be60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', '/home/builder/ktietz/aggregate/tensorflow_recipes/ci_cpu/tensorflow-base_1614583966145/_build_env/bin/x86_64-conda_cos6-linux-gnu-gcc'), ('cuda_compute_capabilities', ['compute_35', 'compute_52', 'compute_60', 'compute_61', 'compute_70', 'compute_75']), ('cuda_version', '10.1'), ('cudnn_version', '7'), ('is_cuda_build', True), ('is_rocm_build', False)])\n",
      "cuda version:  10.1\n",
      "cudNN version:  7\n",
      "TF version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "### -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 24 13:26:13 2021\n",
    "\n",
    "@author: kjsanche\n",
    "\n",
    "Description: \n",
    "A function to load the 5 minute granules from MODIS channel 1 \n",
    "(0.65 microns) and the contrail mask for ML with a CNN.\n",
    "\n",
    "To do:\n",
    "\n",
    "-organize/markdown/comment code\n",
    "\n",
    "\n",
    "Input:\n",
    "Path   (string)\n",
    "\n",
    "        \n",
    "        \n",
    "Output:\n",
    "MODISCh1 (2D uint32)\n",
    "MASK     (2D uint16)\n",
    "\"\"\"\n",
    "###########################################################################\n",
    "#Check/understand if change from relu to sigmoid activation is necessary\n",
    "#########################################################################\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "#from format_input import *\n",
    "from UNET_Functions import unet_model, summary\n",
    "from Sat_contrail_read import Extract_RawDef, extract_img, extract_mask, extract_imglist, get_model_memory_usage\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('/home/kjsanche/Desktop/Projects/loss')\n",
    "from loss_function import *\n",
    "from tensorflow.python.ops.metrics_impl import false_positives, false_negatives\n",
    "import tensorflow.keras.metrics as tfm\n",
    "import tensorflow_addons as tfa\n",
    "from focal_loss import BinaryFocalLoss, SparseCategoricalFocalLoss\n",
    "\n",
    "sys_details = tf.sysconfig.get_build_info()\n",
    "print(sys_details)\n",
    "cudnn_version = sys_details[\"cudnn_version\"]\n",
    "cuda_version = sys_details[\"cuda_version\"]\n",
    "\n",
    "print('cuda version: ', cuda_version)\n",
    "print('cudNN version: ',cudnn_version)\n",
    "print('TF version: ', tf.version.VERSION)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VALIDATION_SPLIT = 0.02\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 3000\n",
    "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
    "IMG_W=512\n",
    "IMG_H=1024\n",
    "N_CHANNELS = 7\n",
    "LEARNING_RATE = 0.0001\n",
    "TFrecord_path ='/home/kjsanche/Desktop/ExternalSSD/SatContrailData/TFrecords/'\n",
    "Models_path ='/home/kjsanche/Desktop/ExternalSSD/SatContrailData/Models/'\n",
    "#TFrecord_path = '/home/kjsanche/Desktop/Projects/Sat_Contrail_Unet/Unet/content/'\n",
    "filenames=tf.io.gfile.glob([TFrecord_path + '*v3.tfrecords'])\n",
    "\n",
    "\n",
    "random.shuffle(filenames)\n",
    "split = int(len(filenames) * VALIDATION_SPLIT)\n",
    "\n",
    "training_filenames = filenames[split:]\n",
    "validation_filenames = filenames[:split]\n",
    "\n",
    "validation_steps = len(validation_filenames) // BATCH_SIZE\n",
    "steps_per_epoch = len(training_filenames)  // BATCH_SIZE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73030cfe-a7cf-4833-bf27-d5fe9926be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr_element(element):\n",
    "    #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "    data = {\n",
    "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
    "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
    "      'raw_label':tf.io.FixedLenFeature([], tf.string),#tf.string = bytestring (not text string)\n",
    "      'raw_image' : tf.io.FixedLenFeature([], tf.string),#tf.string = bytestring (not text string)\n",
    "    }\n",
    "\n",
    "\n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "    height = content['height']\n",
    "    #height=1024\n",
    "    width = content['width']\n",
    "    #width=1024*2\n",
    "    depth = content['depth']\n",
    "    #depth=7\n",
    "    raw_label = content['raw_label']\n",
    "    raw_image = content['raw_image']\n",
    "\n",
    "\n",
    "    #get our 'feature'-- our image -- and reshape it appropriately\n",
    "    feature = tf.io.parse_tensor(raw_image, out_type=tf.float16)\n",
    "\n",
    "    feature = tf.reshape(feature, shape=[height,width,depth])\n",
    "    label = tf.io.parse_tensor(raw_label, out_type=tf.int8)\n",
    "    label = tf.reshape(label, shape=[height,width])\n",
    "    return (feature, label)\n",
    "\n",
    "def get_batched_dataset(filenames):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.map(parse_tfr_element, num_parallel_calls=AUTO)\n",
    "\n",
    "    dataset = dataset.cache() # This dataset fits in RAM\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) \n",
    "    dataset = dataset.prefetch(AUTO) #\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset(training_filenames):\n",
    "    return get_batched_dataset(training_filenames)\n",
    "\n",
    "def get_validation_dataset(training_filenames):\n",
    "    return get_batched_dataset(validation_filenames)\n",
    "\n",
    "def get_dataset_large(tfr_dir:str=\"/home/kjsanche/Desktop/Projects/Sat_Contrail_Unet/Unet/content/\", pattern:str=\"*large_images.tfrecords\"):\n",
    "    files = glob.glob(tfr_dir+pattern, recursive=False)\n",
    "\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(parse_tfr_element)\n",
    "\n",
    "    return dataset\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        #print(i)\n",
    "        #print(display_list[i].shape)\n",
    "        if i == 0:\n",
    "            plt.imshow(np.float32(display_list[i][:,:,7]))#-display_list[i][:,:,1]))\n",
    "        else:\n",
    "            plt.imshow(np.float32(1*display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95823e8e-cea2-4843-a8a1-88d23a1950da",
   "metadata": {},
   "source": [
    "The below code cell uses a lot of memory and therefore should only be used for testing and not be used during training."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f05f075-6b1b-4801-8e8d-e84c6e363970",
   "metadata": {},
   "source": [
    "testdataset = get_dataset_large(tfr_dir = TFrecord_path, pattern = '*.tfrecords')\n",
    "for image, mask in testdataset.take(3):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    display([sample_image, sample_mask])\n",
    "print('mem usage: ', tf.config.experimental.get_memory_usage(\"GPU:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e431f70-397c-4ca4-8f8b-6461838d0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FocalTverskyLoss(targets, inputs, alpha=2, beta=0.5, gamma=5, smooth=1e-4):\n",
    "        '''\n",
    "        ... in the case of α=β=0.5 the Tversky index simplifies to be \n",
    "        the same as the Dice coefficient, which is also equal to the F1 \n",
    "        score. With α=β=1, Equation 2 produces Tanimoto coefficient, and \n",
    "        setting α+β=1 produces the set of Fβ scores. Larger βs weigh \n",
    "        recall higher than precision (by placing more emphasis on false negatives).\n",
    "        '''\n",
    "        targets = tf.cast(targets,tf.float32)\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky"
   ]
  },
  {
   "cell_type": "raw",
   "id": "00a3168b-b2b3-4595-b179-70d77dcfa298",
   "metadata": {},
   "source": [
    "class FalsePositives(tfm.FalsePositives):\n",
    "    def __init__(self, from_logits=False, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._from_logits = from_logits\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        if self._from_logits:\n",
    "            super(FalsePositives, self).update_state(y_true, tf.nn.sigmoid(y_pred), sample_weight)\n",
    "        else:\n",
    "            super(FalsePositives, self).update_state(y_true, y_pred, sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d158a868-eee7-4ead-a31e-399a439eca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________________________________________\n",
      "Layer (type)                              Output Shape                 Param #         Connected to                               \n",
      "==================================================================================================================================\n",
      "input_1 (InputLayer)                      [(None, 512, 1024, 7)]       0                                                          \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                           (None, 512, 1024, 32)        2048            input_1[0][0]                              \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)                   (None, 512, 1024, 32)        0               conv2d[0][0]                               \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                         (None, 512, 1024, 32)        9248            leaky_re_lu[0][0]                          \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)                 (None, 512, 1024, 32)        0               conv2d_1[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)              (None, 256, 512, 32)         0               leaky_re_lu_1[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                         (None, 256, 512, 64)         18496           max_pooling2d[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)                 (None, 256, 512, 64)         0               conv2d_2[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                         (None, 256, 512, 64)         36928           leaky_re_lu_2[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)                 (None, 256, 512, 64)         0               conv2d_3[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)            (None, 128, 256, 64)         0               leaky_re_lu_3[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                         (None, 128, 256, 128)        73856           max_pooling2d_1[0][0]                      \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)                 (None, 128, 256, 128)        0               conv2d_4[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                         (None, 128, 256, 128)        147584          leaky_re_lu_4[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)                 (None, 128, 256, 128)        0               conv2d_5[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)            (None, 64, 128, 128)         0               leaky_re_lu_5[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                         (None, 64, 128, 256)         295168          max_pooling2d_2[0][0]                      \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)                 (None, 64, 128, 256)         0               conv2d_6[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                         (None, 64, 128, 256)         590080          leaky_re_lu_6[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)                 (None, 64, 128, 256)         0               conv2d_7[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "dropout (Dropout)                         (None, 64, 128, 256)         0               leaky_re_lu_7[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)            (None, 32, 64, 256)          0               dropout[0][0]                              \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                         (None, 32, 64, 512)          1180160         max_pooling2d_3[0][0]                      \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)                 (None, 32, 64, 512)          0               conv2d_8[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                         (None, 32, 64, 512)          2359808         leaky_re_lu_8[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)                 (None, 32, 64, 512)          0               conv2d_9[0][0]                             \n",
      "__________________________________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                       (None, 32, 64, 512)          0               leaky_re_lu_9[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspose)        (None, 64, 128, 256)         1179904         dropout_1[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate (Concatenate)                 (None, 64, 128, 512)         0               conv2d_transpose[0][0]                     \n",
      "                                                                                       dropout[0][0]                              \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)                        (None, 64, 128, 256)         1179904         concatenate[0][0]                          \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)                (None, 64, 128, 256)         0               conv2d_10[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)                        (None, 64, 128, 256)         590080          leaky_re_lu_10[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)                (None, 64, 128, 256)         0               conv2d_11[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTranspose)      (None, 128, 256, 128)        295040          leaky_re_lu_11[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)               (None, 128, 256, 256)        0               conv2d_transpose_1[0][0]                   \n",
      "                                                                                       leaky_re_lu_5[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)                        (None, 128, 256, 128)        295040          concatenate_1[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)                (None, 128, 256, 128)        0               conv2d_12[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)                        (None, 128, 256, 128)        147584          leaky_re_lu_12[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)                (None, 128, 256, 128)        0               conv2d_13[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTranspose)      (None, 256, 512, 64)         73792           leaky_re_lu_13[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)               (None, 256, 512, 128)        0               conv2d_transpose_2[0][0]                   \n",
      "                                                                                       leaky_re_lu_3[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)                        (None, 256, 512, 64)         73792           concatenate_2[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)                (None, 256, 512, 64)         0               conv2d_14[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)                        (None, 256, 512, 64)         36928           leaky_re_lu_14[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)                (None, 256, 512, 64)         0               conv2d_15[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTranspose)      (None, 512, 1024, 32)        18464           leaky_re_lu_15[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)               (None, 512, 1024, 64)        0               conv2d_transpose_3[0][0]                   \n",
      "                                                                                       leaky_re_lu_1[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)                        (None, 512, 1024, 32)        18464           concatenate_3[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)                (None, 512, 1024, 32)        0               conv2d_16[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)                        (None, 512, 1024, 32)        9248            leaky_re_lu_16[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)                (None, 512, 1024, 32)        0               conv2d_17[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)                        (None, 512, 1024, 32)        9248            leaky_re_lu_17[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)                (None, 512, 1024, 32)        0               conv2d_18[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)                        (None, 512, 1024, 1)         33              leaky_re_lu_18[0][0]                       \n",
      "__________________________________________________________________________________________________________________________________\n",
      "tf.compat.v1.squeeze (TFOpLambda)         (None, 512, 1024)            0               conv2d_19[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "tf.math.sigmoid (TFOpLambda)              (None, 512, 1024)            0               tf.compat.v1.squeeze[0][0]                 \n",
      "==================================================================================================================================\n",
      "Total params: 8,640,897\n",
      "Trainable params: 8,640,897\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________________________________________\n",
      "mem usage:  34574848\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#gamma>0 reduces the relative loss for well-classified examples \n",
    "#alpha is a weighted term whose value is α for positive(foreground) alpha = 1 does nothing. alpha = 0.25 is best\n",
    "#class and 1-α for negative(background) class.\n",
    "\n",
    "unet = unet_model((IMG_W, IMG_H, N_CHANNELS),n_filters=32,n_classes=1)\n",
    "#loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "#loss=[BinaryFocalLoss(gamma=2,from_logits=True)],\n",
    "\n",
    "#Larger βs weigh recall higher than precision (by placing more emphasis on false negatives)\n",
    "#loss=TverskyLoss(targets, inputs, alpha=0.5, beta=0.5, smooth=1e-6)\n",
    "#loss=FocalTverskyLoss(targets, inputs, alpha=0.5, beta=0.5, gamma=1, smooth=1e-6)\n",
    "unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              loss=[FocalTverskyLoss],\n",
    "              metrics=[tfm.Precision(), tfm.Recall(), tfm.FalseNegatives(), tfm.FalsePositives(), tfm.TruePositives(), tfm.TrueNegatives(), 'binary_accuracy'])\n",
    "#unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "#              loss=[SparseCategoricalFocalLoss(gamma=2,class_weight  = 1,from_logits=True)],\n",
    "#              metrics=['accuracy'])\n",
    "unet.summary(line_length = 130)\n",
    "print('mem usage: ', tf.config.experimental.get_memory_usage(\"GPU:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2b76f90-e07b-4920-917c-2f4e1dbe8a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.013\n",
      "WARNING:tensorflow:AutoGraph could not transform <function parse_tfr_element at 0x7fc8643c81f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function parse_tfr_element at 0x7fc8643c81f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "<PrefetchDataset shapes: ((2, None, None, None), (2, None, None)), types: (tf.float16, tf.int8)>\n",
      "Epoch 1/3000\n",
      "31/31 [==============================] - 64s 618ms/step - loss: 0.9997 - precision: 2.8231e-04 - recall: 0.1822 - false_negatives: 2799.2500 - false_positives: 1651846.6562 - true_positives: 480.9375 - true_negatives: 15613609.2500 - binary_accuracy: 0.8496\n",
      "Epoch 2/3000\n",
      "31/31 [==============================] - 19s 606ms/step - loss: 0.9997 - precision: 4.1313e-04 - recall: 0.0050 - false_negatives: 2773.0938 - false_positives: 33845.5625 - true_positives: 18.3750 - true_negatives: 17232098.4062 - binary_accuracy: 0.9979\n",
      "Epoch 3/3000\n",
      "31/31 [==============================] - 19s 608ms/step - loss: 0.9995 - precision: 5.8011e-04 - recall: 8.4872e-04 - false_negatives: 3303.5625 - false_positives: 34729.0312 - true_positives: 2.9688 - true_negatives: 17230700.0000 - binary_accuracy: 0.9984\n",
      "Epoch 4/3000\n",
      "31/31 [==============================] - 19s 608ms/step - loss: 0.9994 - precision: 6.9984e-04 - recall: 0.0085 - false_negatives: 4365.1562 - false_positives: 41963.8125 - true_positives: 30.4062 - true_negatives: 17222376.9375 - binary_accuracy: 0.9963\n",
      "Epoch 5/3000\n",
      "31/31 [==============================] - 19s 610ms/step - loss: 0.9998 - precision: 4.6716e-04 - recall: 6.9389e-04 - false_negatives: 1955.4375 - false_positives: 3476.5625 - true_positives: 1.5000 - true_negatives: 17263302.5000 - binary_accuracy: 0.9997\n",
      "Epoch 6/3000\n",
      "31/31 [==============================] - 19s 607ms/step - loss: 0.9648 - precision: 7.7246e-04 - recall: 7.2709e-04 - false_negatives: 4504.5938 - false_positives: 3780.4062 - true_positives: 3.1250 - true_negatives: 17260448.7188 - binary_accuracy: 0.9995\n",
      "Epoch 7/3000\n",
      "31/31 [==============================] - 19s 604ms/step - loss: 0.8203 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 1650.9688 - false_positives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 17267085.5938 - binary_accuracy: 0.9999\n",
      "Epoch 8/3000\n",
      "31/31 [==============================] - 19s 602ms/step - loss: 0.9029 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 3397.5625 - false_positives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 17265338.7188 - binary_accuracy: 0.9998\n",
      "Epoch 9/3000\n",
      "31/31 [==============================] - 19s 602ms/step - loss: 0.8704 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 2593.1875 - false_positives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 17266142.9375 - binary_accuracy: 0.9998\n",
      "Epoch 10/3000\n",
      "31/31 [==============================] - 19s 604ms/step - loss: 0.8042 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 1443.3125 - false_positives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 17267291.4062 - binary_accuracy: 0.9999\n",
      "Epoch 11/3000\n",
      "31/31 [==============================] - 19s 604ms/step - loss: 0.9788 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 4142.5625 - false_positives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 17264593.3125 - binary_accuracy: 0.9998\n",
      "Epoch 12/3000\n",
      "15/31 [=============>................] - ETA: 9s - loss: 0.8978 - precision: 0.0000e+00 - recall: 0.0000e+00 - false_negatives: 2356.0667 - false_positives: 0.0000e+00 - true_positives: 0.0000e+00 - true_negatives: 8386251.9333 - binary_accuracy: 0.9996 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-7243e9e0e856>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(get_model_memory_usage(BATCH_SIZE, unet))\n",
    "\n",
    "\n",
    "training_data = get_training_dataset(training_filenames)\n",
    "validation_data = get_training_dataset(validation_filenames)\n",
    "print(training_data)\n",
    "model_history = unet.fit(training_data, validation_data=validation_data, validation_steps=validation_steps, steps_per_epoch=steps_per_epoch, epochs=EPOCHS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96176be-c614-4132-96af-a02156f60c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unet.save_weights(Models_path+'model')\n",
    "#unet = tf.keras.models.load_model(Models_path+'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbf810-7398-46ca-914a-1c3537bb5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(2,2, figsize=(15,15))\n",
    "\n",
    "axs[0,0].plot(model_history.history['binary_accuracy'])\n",
    "axs[0,0].plot(model_history.history['val_binary_accuracy'])\n",
    "axs[0,0].set_title('model accuracy')\n",
    "axs[0,0].set_ylabel('accuracy')\n",
    "\n",
    "#axs[0].legend(['train', 'val'], loc='upper left')\n",
    "#axs[0].show()\n",
    "\n",
    "axs[1,0].plot(model_history.history['loss'])\n",
    "axs[1,0].plot(model_history.history['val_loss'])\n",
    "axs[1,0].set_title('model loss')\n",
    "axs[1,0].set_ylabel('loss')\n",
    "\n",
    "axs[1,0].legend(['train', 'val'], loc='upper right')\n",
    "\n",
    "\n",
    "\n",
    "F1 = 2*np.divide(np.multiply(model_history.history['precision'],model_history.history['recall']), np.add(model_history.history['precision'], model_history.history['recall']))\n",
    "F1_val = 2*np.divide(np.multiply(model_history.history['val_precision'],model_history.history['val_recall']), np.add(model_history.history['val_precision'], model_history.history['val_recall']))\n",
    "FP = model_history.history['false_positives']\n",
    "TP = model_history.history['true_positives']\n",
    "FN = model_history.history['false_negatives']\n",
    "TN = model_history.history['true_negatives']\n",
    "MCC = np.subtract(np.multiply(TP,TN),np.multiply(FP,FN))/np.sqrt(np.multiply(np.multiply(np.add(TP,FP),np.add(TP,FN)), np.multiply(np.add(TN,FP),np.add(TN,FN))))\n",
    "FP = model_history.history['val_false_positives']\n",
    "TP = model_history.history['val_true_positives']\n",
    "FN = model_history.history['val_false_negatives']\n",
    "TN = model_history.history['val_true_negatives']\n",
    "MCC_val = np.subtract(np.multiply(TP,TN),np.multiply(FP,FN))/np.sqrt(np.multiply(np.multiply(np.add(TP,FP),np.add(TP,FN)), np.multiply(np.add(TN,FP),np.add(TN,FN))))\n",
    "\n",
    "axs[0,1].plot(F1)\n",
    "axs[0,1].plot(F1_val)\n",
    "axs[0,1].set_title('model F1 score')\n",
    "axs[0,1].set_ylabel('F1')\n",
    "axs[0,1].set_xlabel('epoch')\n",
    "\n",
    "axs[1,1].plot(MCC)\n",
    "axs[1,1].plot(MCC_val)\n",
    "axs[1,1].set_title('model MCC')\n",
    "axs[1,1].set_ylabel('MCC')\n",
    "axs[1,1].set_xlabel('epoch')\n",
    "\n",
    "\n",
    "i = 1\n",
    "while os.path.exists(Models_path+\"Model%s.png\" % i):\n",
    "    i += 1\n",
    "plt.savefig(Models_path+\"Model%s.png\" % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a7844-4741-4845-98b4-556e730899df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883bd4b-b30e-40e4-a416-21cfd7fad22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    #print(pred_mask.shape)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    \"\"\"\n",
    "    Displays the first image of each of the num batches\n",
    "    \"\"\"\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = unet.predict(image[tf.newaxis,:,:,:])\n",
    "            print(mask)\n",
    "            test=  np.squeeze(pred_mask)\n",
    "            print(test.shape)\n",
    "            #display([image, mask, test])\n",
    "            display([image, mask, create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a49a1-eab7-4c90-bb6c-b69eba857245",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = get_dataset_large(tfr_dir = TFrecord_path, pattern = '*.tfrecords')\n",
    "print(testdataset)\n",
    "show_predictions(testdataset, 10)\n",
    "\n",
    "#####################change display to show 11microns -12 microns or whatever it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c91ac-32a9-4539-b3d1-0503a4cb985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_mask = unet.predict(image[tf.newaxis,:,:,:])\n",
    "plt.imshow(\n",
    "    pr_mask[0]\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdcdac-28a9-448e-b81e-5902515ac246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
