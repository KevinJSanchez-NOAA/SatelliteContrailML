{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ea7090-2a21-46f5-ae21-e3e50b2f77f2",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## Import Packages and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deb437a0-ae1e-4c58-83f8-4f78626be60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', '/home/builder/ktietz/aggregate/tensorflow_recipes/ci_cpu/tensorflow-base_1614583966145/_build_env/bin/x86_64-conda_cos6-linux-gnu-gcc'), ('cuda_compute_capabilities', ['compute_35', 'compute_52', 'compute_60', 'compute_61', 'compute_70', 'compute_75']), ('cuda_version', '10.1'), ('cudnn_version', '7'), ('is_cuda_build', True), ('is_rocm_build', False)])\n",
      "cuda version:  10.1\n",
      "cudNN version:  7\n",
      "TF version:  2.4.1\n"
     ]
    }
   ],
   "source": [
    "### -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon May 24 13:26:13 2021\n",
    "\n",
    "@author: kjsanche\n",
    "\n",
    "Description: \n",
    "A function to load the 5 minute granules from MODIS channel 1 \n",
    "(0.65 microns) and the contrail mask for ML with a CNN.\n",
    "\n",
    "To do:\n",
    "ASAP:\n",
    "-create blacklist of images to exclude (if images are to big)\n",
    "-separate testing data\n",
    "-plot testing data vs mask\n",
    "\n",
    "\n",
    "\n",
    "lower priority:\n",
    "-optimize image shape by transforming back to original satellite swath projection\n",
    "-save and set up to load data as tfrecord\n",
    "-organize/markdown/comment code\n",
    "\n",
    "\n",
    "Input:\n",
    "Path   (string)\n",
    "\n",
    "        \n",
    "        \n",
    "Output:\n",
    "MODISCh1 (2D uint32)\n",
    "MASK     (2D uint16)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import struct\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "#from format_input import *\n",
    "from UNET_Functions import unet_model, summary\n",
    "from Sat_contrail_read import Extract_RawDef, extract_img, extract_mask, extract_imglist, get_model_memory_usage\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('/home/kjsanche/Desktop/Projects/loss')\n",
    "from loss_function import *\n",
    "import tensorflow_addons as tfa\n",
    "from focal_loss import BinaryFocalLoss, SparseCategoricalFocalLoss\n",
    "\n",
    "sys_details = tf.sysconfig.get_build_info()\n",
    "print(sys_details)\n",
    "cudnn_version = sys_details[\"cudnn_version\"]\n",
    "cuda_version = sys_details[\"cuda_version\"]\n",
    "\n",
    "print('cuda version: ', cuda_version)\n",
    "print('cudNN version: ',cudnn_version)\n",
    "print('TF version: ', tf.version.VERSION)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "VALIDATION_SPLIT = 0.20\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 30\n",
    "AUTO = tf.data.experimental.AUTOTUNE # used in tf.data.Dataset API\n",
    "IMG_W=1024\n",
    "IMG_H=2048\n",
    "N_CHANNELS = 7\n",
    "TFrecord_path ='/home/kjsanche/Desktop/ExternalSSD/SatContrailData/TFrecords/'\n",
    "#TFrecord_path = '/home/kjsanche/Desktop/Projects/Sat_Contrail_Unet/Unet/content/'\n",
    "filenames=tf.io.gfile.glob([TFrecord_path + '*.tfrecords'])\n",
    "\n",
    "\n",
    "random.shuffle(filenames)\n",
    "split = int(len(filenames) * VALIDATION_SPLIT)\n",
    "\n",
    "training_filenames = filenames[split:]\n",
    "validation_filenames = filenames[:split]\n",
    "\n",
    "validation_steps = len(validation_filenames) #int(3670 // len(filenames) * len(validation_filenames)) // BATCH_SIZE\n",
    "steps_per_epoch = len(training_filenames) #int(3670 // len(filenames) * len(training_filenames)) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73030cfe-a7cf-4833-bf27-d5fe9926be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfr_element(element):\n",
    "    #use the same structure as above; it's kinda an outline of the structure we now want to create\n",
    "    data = {\n",
    "      'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "      'width':tf.io.FixedLenFeature([], tf.int64),\n",
    "      'depth':tf.io.FixedLenFeature([], tf.int64),\n",
    "      'raw_label':tf.io.FixedLenFeature([], tf.string),#tf.string = bytestring (not text string)\n",
    "      'raw_image' : tf.io.FixedLenFeature([], tf.string),#tf.string = bytestring (not text string)\n",
    "    }\n",
    "\n",
    "\n",
    "    content = tf.io.parse_single_example(element, data)\n",
    "\n",
    "    height = content['height']\n",
    "    #height=1024\n",
    "    width = content['width']\n",
    "    #width=1024*2\n",
    "    depth = content['depth']\n",
    "    #depth=7\n",
    "    raw_label = content['raw_label']\n",
    "    raw_image = content['raw_image']\n",
    "\n",
    "\n",
    "    #get our 'feature'-- our image -- and reshape it appropriately\n",
    "    feature = tf.io.parse_tensor(raw_image, out_type=tf.float16)\n",
    "\n",
    "    feature = tf.reshape(feature, shape=[height,width,depth])\n",
    "    label = tf.io.parse_tensor(raw_label, out_type=tf.int8)\n",
    "    label = tf.reshape(label, shape=[height,width])\n",
    "    return (feature, label)\n",
    "\n",
    "def get_batched_dataset(filenames):\n",
    "    option_no_order = tf.data.Options()\n",
    "    option_no_order.experimental_deterministic = False\n",
    "\n",
    "    dataset = tf.data.Dataset.list_files(filenames)\n",
    "    dataset = dataset.with_options(option_no_order)\n",
    "    dataset = dataset.interleave(tf.data.TFRecordDataset, cycle_length=16, num_parallel_calls=AUTO)\n",
    "    dataset = dataset.map(parse_tfr_element, num_parallel_calls=AUTO)\n",
    "\n",
    "    dataset = dataset.cache() # This dataset fits in RAM\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True) \n",
    "    dataset = dataset.prefetch(AUTO) #\n",
    "\n",
    "    return dataset\n",
    "\n",
    "def get_training_dataset(training_filenames):\n",
    "    return get_batched_dataset(training_filenames)\n",
    "\n",
    "def get_validation_dataset(training_filenames):\n",
    "    return get_batched_dataset(validation_filenames)\n",
    "\n",
    "def get_dataset_large(tfr_dir:str=\"/home/kjsanche/Desktop/Projects/Sat_Contrail_Unet/Unet/content/\", pattern:str=\"*large_images.tfrecords\"):\n",
    "    files = glob.glob(tfr_dir+pattern, recursive=False)\n",
    "\n",
    "    #create the dataset\n",
    "    dataset = tf.data.TFRecordDataset(files)\n",
    "\n",
    "    #pass every single feature through our mapping function\n",
    "    dataset = dataset.map(parse_tfr_element)\n",
    "\n",
    "    return dataset\n",
    "def display(display_list):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "\n",
    "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        #print(i)\n",
    "        #print(display_list[i].shape)\n",
    "        if i == 0:\n",
    "            plt.imshow(np.float32(display_list[i][:,:,0]-display_list[i][:,:,1]))\n",
    "        else:\n",
    "            plt.imshow(np.float32(1*display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95823e8e-cea2-4843-a8a1-88d23a1950da",
   "metadata": {},
   "source": [
    "The below code cell uses a lot of memory and therefore should only be used for testing and not be used during training."
   ]
  },
  {
   "cell_type": "raw",
   "id": "febce525-d568-481f-b96d-5ab0c1858b38",
   "metadata": {},
   "source": [
    "testdataset = get_dataset_large(tfr_dir = TFrecord_path, pattern = '*.tfrecords')\n",
    "for image, mask in testdataset.take(3):\n",
    "    sample_image, sample_mask = image, mask\n",
    "    display([sample_image, sample_mask])\n",
    "print('mem usage: ', tf.config.experimental.get_memory_usage(\"GPU:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e431f70-397c-4ca4-8f8b-6461838d0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TverskyLoss(targets, inputs, alpha=0.5, beta=0.5, smooth=1e-6):\n",
    "        '''\n",
    "        ... in the case of α=β=0.5 the Tversky index simplifies to be \n",
    "        the same as the Dice coefficient, which is also equal to the F1 \n",
    "        score. With α=β=1, Equation 2 produces Tanimoto coefficient, and \n",
    "        setting α+β=1 produces the set of Fβ scores. Larger βs weigh \n",
    "        recall higher than precision (by placing more emphasis on false negatives).\n",
    "        '''\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "       \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        \n",
    "        return 1 - Tversky\n",
    "    \n",
    "\n",
    "def FocalTverskyLoss(targets, inputs, alpha=0.5, beta=0.5, gamma=1, smooth=1e-6):\n",
    "    \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        \n",
    "        #True Positives, False Positives & False Negatives\n",
    "        TP = K.sum((inputs * targets))\n",
    "        FP = K.sum(((1-targets) * inputs))\n",
    "        FN = K.sum((targets * (1-inputs)))\n",
    "               \n",
    "        Tversky = (TP + smooth) / (TP + alpha*FP + beta*FN + smooth)  \n",
    "        FocalTversky = K.pow((1 - Tversky), gamma)\n",
    "        \n",
    "        return FocalTversky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d158a868-eee7-4ead-a31e-399a439eca29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________________________________________\n",
      "Layer (type)                              Output Shape                 Param #         Connected to                               \n",
      "==================================================================================================================================\n",
      "input_2 (InputLayer)                      [(None, 1024, 2048, 7)]      0                                                          \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)                        (None, 1024, 2048, 32)       2048            input_2[0][0]                              \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)                        (None, 1024, 2048, 32)       9248            conv2d_20[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)            (None, 512, 1024, 32)        0               conv2d_21[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)                        (None, 512, 1024, 64)        18496           max_pooling2d_4[0][0]                      \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)                        (None, 512, 1024, 64)        36928           conv2d_22[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)            (None, 256, 512, 64)         0               conv2d_23[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)                        (None, 256, 512, 128)        73856           max_pooling2d_5[0][0]                      \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)                        (None, 256, 512, 128)        147584          conv2d_24[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)            (None, 128, 256, 128)        0               conv2d_25[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)                        (None, 128, 256, 256)        295168          max_pooling2d_6[0][0]                      \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)                        (None, 128, 256, 256)        590080          conv2d_26[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                       (None, 128, 256, 256)        0               conv2d_27[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)            (None, 64, 128, 256)         0               dropout_2[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)                        (None, 64, 128, 512)         1180160         max_pooling2d_7[0][0]                      \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)                        (None, 64, 128, 512)         2359808         conv2d_28[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)                       (None, 64, 128, 512)         0               conv2d_29[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTranspose)      (None, 128, 256, 256)        1179904         dropout_3[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)               (None, 128, 256, 512)        0               conv2d_transpose_4[0][0]                   \n",
      "                                                                                       dropout_2[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)                        (None, 128, 256, 256)        1179904         concatenate_4[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)                        (None, 128, 256, 256)        590080          conv2d_30[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTranspose)      (None, 256, 512, 128)        295040          conv2d_31[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)               (None, 256, 512, 256)        0               conv2d_transpose_5[0][0]                   \n",
      "                                                                                       conv2d_25[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)                        (None, 256, 512, 128)        295040          concatenate_5[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)                        (None, 256, 512, 128)        147584          conv2d_32[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTranspose)      (None, 512, 1024, 64)        73792           conv2d_33[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)               (None, 512, 1024, 128)       0               conv2d_transpose_6[0][0]                   \n",
      "                                                                                       conv2d_23[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)                        (None, 512, 1024, 64)        73792           concatenate_6[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)                        (None, 512, 1024, 64)        36928           conv2d_34[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTranspose)      (None, 1024, 2048, 32)       18464           conv2d_35[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)               (None, 1024, 2048, 64)       0               conv2d_transpose_7[0][0]                   \n",
      "                                                                                       conv2d_21[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)                        (None, 1024, 2048, 32)       18464           concatenate_7[0][0]                        \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)                        (None, 1024, 2048, 32)       9248            conv2d_36[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)                        (None, 1024, 2048, 32)       9248            conv2d_37[0][0]                            \n",
      "__________________________________________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)                        (None, 1024, 2048, 3)        99              conv2d_38[0][0]                            \n",
      "==================================================================================================================================\n",
      "Total params: 8,640,963\n",
      "Trainable params: 8,640,963\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________________________________________\n",
      "mem usage:  70352896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#gamma>0 reduces the relative loss for well-classified examples \n",
    "#alpha is a weighted term whose value is α for positive(foreground) alpha = 1 does nothing. alpha = 0.25 is best\n",
    "#class and 1-α for negative(background) class.\n",
    "\n",
    "unet = unet_model((IMG_W, IMG_H, N_CHANNELS),n_filters=32,n_classes=3)\n",
    "#loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#loss=tfa.losses.SigmoidFocalCrossEntropy(),\n",
    "#loss=[BinaryFocalLoss(gamma=2,from_logits=True)],\n",
    "#Larger βs weigh recall higher than precision (by placing more emphasis on false negatives)\n",
    "#FocalTverskyLoss(targets, inputs, alpha=ALPHA, beta=BETA, gamma=GAMMA, smooth=1e-6)\n",
    "unet.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001),\n",
    "              loss=[SparseCategoricalFocalLoss(gamma=2,class_weight  = 1,from_logits=True)],\n",
    "              metrics=[tf.keras.metrics.FalseNegatives(), tf.keras.metrics.FalsePositives(), 'accuracy'])\n",
    "unet.summary(line_length = 130)\n",
    "print('mem usage: ', tf.config.experimental.get_memory_usage(\"GPU:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba8cae-aba7-43a5-b799-b3e5b649573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_data = get_training_dataset(training_filenames)\n",
    "#test1, test2 = tuple(zip(*training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b76f90-e07b-4920-917c-2f4e1dbe8a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.837\n",
      "mem usage:  70352896\n",
      "<PrefetchDataset shapes: ((1, 1024, 2048, 7), (1, 1024, 2048)), types: (tf.float16, tf.int8)>\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/focal_loss/_categorical_focal_loss.py:311 call  *\n        from_logits=self.from_logits)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/focal_loss/_categorical_focal_loss.py:180 sparse_categorical_focal_loss  *\n        class_weight = tf.gather(class_weight, y_true, axis=0,\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:4826 gather_v2\n        return gather(\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:4815 gather\n        return gen_array_ops.gather_v2(params, indices, axis, name=name)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:3800 gather_v2\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be at least rank 1 but is rank 0 for '{{node SparseCategoricalFocalLoss/GatherV2_1}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, batch_dims=0](SparseCategoricalFocalLoss/Const_1, SparseCategoricalFocalLoss/Cast, SparseCategoricalFocalLoss/GatherV2_1/axis)' with input shapes: [], [1,1024,2048], [].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6367af0d69ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_training_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/focal_loss/_categorical_focal_loss.py:311 call  *\n        from_logits=self.from_logits)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/focal_loss/_categorical_focal_loss.py:180 sparse_categorical_focal_loss  *\n        class_weight = tf.gather(class_weight, y_true, axis=0,\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **\n        return target(*args, **kwargs)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:4826 gather_v2\n        return gather(\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py:4815 gather\n        return gen_array_ops.gather_v2(params, indices, axis, name=name)\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py:3800 gather_v2\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py:748 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:590 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:3528 _create_op_internal\n        ret = Operation(\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:2015 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    /home/kjsanche/anaconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:1856 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Shape must be at least rank 1 but is rank 0 for '{{node SparseCategoricalFocalLoss/GatherV2_1}} = GatherV2[Taxis=DT_INT32, Tindices=DT_INT64, Tparams=DT_FLOAT, batch_dims=0](SparseCategoricalFocalLoss/Const_1, SparseCategoricalFocalLoss/Cast, SparseCategoricalFocalLoss/GatherV2_1/axis)' with input shapes: [], [1,1024,2048], [].\n"
     ]
    }
   ],
   "source": [
    "print(get_model_memory_usage(BATCH_SIZE, unet))\n",
    "\n",
    "\n",
    "print('mem usage: ', tf.config.experimental.get_memory_usage(\"GPU:0\"))\n",
    "training_data = get_training_dataset(training_filenames)\n",
    "print(training_data)\n",
    "model_history = unet.fit(training_data, steps_per_epoch=steps_per_epoch, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dbf810-7398-46ca-914a-1c3537bb5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(model_history.history[\"falsepositives\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2883bd4b-b30e-40e4-a416-21cfd7fad22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    #print(pred_mask.shape)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset=None, num=1):\n",
    "    \"\"\"\n",
    "    Displays the first image of each of the num batches\n",
    "    \"\"\"\n",
    "    if dataset:\n",
    "        for image, mask in dataset.take(num):\n",
    "            pred_mask = unet.predict(image[tf.newaxis,:,:,:])\n",
    "            print(mask)\n",
    "            test=  np.squeeze(pred_mask)\n",
    "            print(test.shape)\n",
    "            #display([image, mask, test])\n",
    "            display([image, mask, create_mask(pred_mask)])\n",
    "    else:\n",
    "        display([sample_image, sample_mask,\n",
    "             create_mask(unet.predict(sample_image[tf.newaxis, ...]))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a49a1-eab7-4c90-bb6c-b69eba857245",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdataset = get_dataset_large(tfr_dir = TFrecord_path, pattern = '*.tfrecords')\n",
    "print(testdataset)\n",
    "show_predictions(testdataset, 10)\n",
    "\n",
    "#####################change display to show 11microns -12 microns or whatever it should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c91ac-32a9-4539-b3d1-0503a4cb985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_mask = unet.predict(image[tf.newaxis,:,:,:])\n",
    "plt.imshow(\n",
    "    pr_mask[0]\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bdcdac-28a9-448e-b81e-5902515ac246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
